<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html>
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>D:\Data\lu\移动深度学习实战\第12章\code\tflite_sample\jni\java\NativeInterpreterWrapper.java.html</title>
<meta name="Generator" content="Vim/8.1">
<meta name="plugin-version" content="vim7.4_v2">
<meta name="syntax" content="java">
<meta name="settings" content="number_lines,use_css,pre_wrap,no_foldcolumn,expand_tabs,line_ids,prevent_copy=">
<meta name="colorscheme" content="desert">
<style type="text/css">
<!--
pre { white-space: pre-wrap; font-family: monospace; color: #ffffff; background-color: #333333; }
body { font-family: monospace; color: #ffffff; background-color: #333333; }
* { font-size: 1em; }
.PreProc { color: #cd5c5c; }
.Type { color: #bdb76b; font-weight: bold; }
.LineNr { color: #ffff00; }
.Comment { color: #87ceeb; }
.Constant { color: #ffa0a0; }
.Statement { color: #f0e68c; font-weight: bold; }
-->
</style>

<script type='text/javascript'>
<!--

/* function to open any folds containing a jumped-to line before jumping to it */
function JumpToLine()
{
  var lineNum;
  lineNum = window.location.hash;
  lineNum = lineNum.substr(1); /* strip off '#' */

  if (lineNum.indexOf('L') == -1) {
    lineNum = 'L'+lineNum;
  }
  lineElem = document.getElementById(lineNum);
  /* Always jump to new location even if the line was hidden inside a fold, or
   * we corrected the raw number to a line ID.
   */
  if (lineElem) {
    lineElem.scrollIntoView(true);
  }
  return true;
}
if ('onhashchange' in window) {
  window.onhashchange = JumpToLine;
}

-->
</script>
</head>
<body onload='JumpToLine();'>
<pre id='vimCodeElement'>
<span id="L1" class="LineNr">  1 </span><span class="PreProc">package</span> org.tensorflow.lite;
<span id="L2" class="LineNr">  2 </span>
<span id="L3" class="LineNr">  3 </span><span class="PreProc">import</span> java.nio.ByteBuffer;
<span id="L4" class="LineNr">  4 </span><span class="PreProc">import</span> java.nio.ByteOrder;
<span id="L5" class="LineNr">  5 </span><span class="PreProc">import</span> java.nio.MappedByteBuffer;
<span id="L6" class="LineNr">  6 </span><span class="PreProc">import</span> java.util.ArrayList;
<span id="L7" class="LineNr">  7 </span><span class="PreProc">import</span> java.util.HashMap;
<span id="L8" class="LineNr">  8 </span><span class="PreProc">import</span> java.util.List;
<span id="L9" class="LineNr">  9 </span><span class="PreProc">import</span> java.util.Map;
<span id="L10" class="LineNr"> 10 </span>
<span id="L11" class="LineNr"> 11 </span><span class="Type">final</span> <span class="Type">class</span> NativeInterpreterWrapper <span class="Type">implements</span> AutoCloseable {
<span id="L12" class="LineNr"> 12 </span>
<span id="L13" class="LineNr"> 13 </span>  NativeInterpreterWrapper(String modelPath) {
<span id="L14" class="LineNr"> 14 </span>    <span class="Type">this</span>(modelPath, <span class="Comment">/* options= */</span> <span class="Constant">null</span>);
<span id="L15" class="LineNr"> 15 </span>  }
<span id="L16" class="LineNr"> 16 </span>
<span id="L17" class="LineNr"> 17 </span>  NativeInterpreterWrapper(String modelPath, Interpreter.Options options) {
<span id="L18" class="LineNr"> 18 </span>    <span class="Type">long</span> errorHandle = createErrorReporter(ERROR_BUFFER_SIZE);
<span id="L19" class="LineNr"> 19 </span>    <span class="Type">long</span> modelHandle = createModel(modelPath, errorHandle);
<span id="L20" class="LineNr"> 20 </span>    init(errorHandle, modelHandle, options);
<span id="L21" class="LineNr"> 21 </span>  }
<span id="L22" class="LineNr"> 22 </span>
<span id="L23" class="LineNr"> 23 </span>  NativeInterpreterWrapper(ByteBuffer byteBuffer) {
<span id="L24" class="LineNr"> 24 </span>    <span class="Type">this</span>(byteBuffer, <span class="Comment">/* options= */</span> <span class="Constant">null</span>);
<span id="L25" class="LineNr"> 25 </span>  }
<span id="L26" class="LineNr"> 26 </span>
<span id="L27" class="LineNr"> 27 </span>  NativeInterpreterWrapper(ByteBuffer buffer, Interpreter.Options options) {
<span id="L28" class="LineNr"> 28 </span>    <span class="Statement">if</span> (buffer == <span class="Constant">null</span>
<span id="L29" class="LineNr"> 29 </span>        || (!(buffer <span class="Statement">instanceof</span> MappedByteBuffer)
<span id="L30" class="LineNr"> 30 </span>            &amp;&amp; (!buffer.isDirect() || buffer.order() != ByteOrder.nativeOrder()))) {
<span id="L31" class="LineNr"> 31 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(
<span id="L32" class="LineNr"> 32 </span>          <span class="Constant">&quot;Model ByteBuffer should be either a MappedByteBuffer of the model file, or a direct &quot;</span>
<span id="L33" class="LineNr"> 33 </span>              + <span class="Constant">&quot;ByteBuffer using ByteOrder.nativeOrder() which contains bytes of model content.&quot;</span>);
<span id="L34" class="LineNr"> 34 </span>    }
<span id="L35" class="LineNr"> 35 </span>    <span class="Type">this</span>.modelByteBuffer = buffer;
<span id="L36" class="LineNr"> 36 </span>    <span class="Type">long</span> errorHandle = createErrorReporter(ERROR_BUFFER_SIZE);
<span id="L37" class="LineNr"> 37 </span>    <span class="Type">long</span> modelHandle = createModelWithBuffer(modelByteBuffer, errorHandle);
<span id="L38" class="LineNr"> 38 </span>    init(errorHandle, modelHandle, options);
<span id="L39" class="LineNr"> 39 </span>  }
<span id="L40" class="LineNr"> 40 </span>
<span id="L41" class="LineNr"> 41 </span>  <span class="Type">private</span> <span class="Type">void</span> init(<span class="Type">long</span> errorHandle, <span class="Type">long</span> modelHandle, Interpreter.Options options) {
<span id="L42" class="LineNr"> 42 </span>    <span class="Statement">if</span> (options == <span class="Constant">null</span>) {
<span id="L43" class="LineNr"> 43 </span>      options = <span class="Statement">new</span> Interpreter.Options();
<span id="L44" class="LineNr"> 44 </span>    }
<span id="L45" class="LineNr"> 45 </span>    <span class="Type">this</span>.errorHandle = errorHandle;
<span id="L46" class="LineNr"> 46 </span>    <span class="Type">this</span>.modelHandle = modelHandle;
<span id="L47" class="LineNr"> 47 </span>    <span class="Type">this</span>.interpreterHandle = createInterpreter(modelHandle, errorHandle, options.numThreads);
<span id="L48" class="LineNr"> 48 </span>    <span class="Type">this</span>.inputTensors = <span class="Statement">new</span> Tensor[getInputCount(interpreterHandle)];
<span id="L49" class="LineNr"> 49 </span>    <span class="Type">this</span>.outputTensors = <span class="Statement">new</span> Tensor[getOutputCount(interpreterHandle)];
<span id="L50" class="LineNr"> 50 </span>    <span class="Statement">if</span> (options.useNNAPI != <span class="Constant">null</span>) {
<span id="L51" class="LineNr"> 51 </span>      setUseNNAPI(options.useNNAPI.booleanValue());
<span id="L52" class="LineNr"> 52 </span>    }
<span id="L53" class="LineNr"> 53 </span>    <span class="Statement">if</span> (options.allowFp16PrecisionForFp32 != <span class="Constant">null</span>) {
<span id="L54" class="LineNr"> 54 </span>      allowFp16PrecisionForFp32(
<span id="L55" class="LineNr"> 55 </span>          interpreterHandle, options.allowFp16PrecisionForFp32.booleanValue());
<span id="L56" class="LineNr"> 56 </span>    }
<span id="L57" class="LineNr"> 57 </span>    <span class="Statement">if</span> (options.allowBufferHandleOutput != <span class="Constant">null</span>) {
<span id="L58" class="LineNr"> 58 </span>      allowBufferHandleOutput(interpreterHandle, options.allowBufferHandleOutput.booleanValue());
<span id="L59" class="LineNr"> 59 </span>    }
<span id="L60" class="LineNr"> 60 </span>    <span class="Statement">for</span> (Delegate delegate : options.delegates) {
<span id="L61" class="LineNr"> 61 </span>      applyDelegate(interpreterHandle, errorHandle, delegate.getNativeHandle());
<span id="L62" class="LineNr"> 62 </span>      delegates.add(delegate);
<span id="L63" class="LineNr"> 63 </span>    }
<span id="L64" class="LineNr"> 64 </span>    allocateTensors(interpreterHandle, errorHandle);
<span id="L65" class="LineNr"> 65 </span>    <span class="Type">this</span>.isMemoryAllocated = <span class="Constant">true</span>;
<span id="L66" class="LineNr"> 66 </span>  }
<span id="L67" class="LineNr"> 67 </span>
<span id="L68" class="LineNr"> 68 </span>  <span class="PreProc">@Override</span>
<span id="L69" class="LineNr"> 69 </span>  <span class="Type">public</span> <span class="Type">void</span> close() {
<span id="L70" class="LineNr"> 70 </span>    <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; inputTensors.length; ++i) {
<span id="L71" class="LineNr"> 71 </span>      <span class="Statement">if</span> (inputTensors[i] != <span class="Constant">null</span>) {
<span id="L72" class="LineNr"> 72 </span>        inputTensors[i].close();
<span id="L73" class="LineNr"> 73 </span>        inputTensors[i] = <span class="Constant">null</span>;
<span id="L74" class="LineNr"> 74 </span>      }
<span id="L75" class="LineNr"> 75 </span>    }
<span id="L76" class="LineNr"> 76 </span>    <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; outputTensors.length; ++i) {
<span id="L77" class="LineNr"> 77 </span>      <span class="Statement">if</span> (outputTensors[i] != <span class="Constant">null</span>) {
<span id="L78" class="LineNr"> 78 </span>        outputTensors[i].close();
<span id="L79" class="LineNr"> 79 </span>        outputTensors[i] = <span class="Constant">null</span>;
<span id="L80" class="LineNr"> 80 </span>      }
<span id="L81" class="LineNr"> 81 </span>    }
<span id="L82" class="LineNr"> 82 </span>    delete(errorHandle, modelHandle, interpreterHandle);
<span id="L83" class="LineNr"> 83 </span>    errorHandle = <span class="Constant">0</span>;
<span id="L84" class="LineNr"> 84 </span>    modelHandle = <span class="Constant">0</span>;
<span id="L85" class="LineNr"> 85 </span>    interpreterHandle = <span class="Constant">0</span>;
<span id="L86" class="LineNr"> 86 </span>    modelByteBuffer = <span class="Constant">null</span>;
<span id="L87" class="LineNr"> 87 </span>    inputsIndexes = <span class="Constant">null</span>;
<span id="L88" class="LineNr"> 88 </span>    outputsIndexes = <span class="Constant">null</span>;
<span id="L89" class="LineNr"> 89 </span>    isMemoryAllocated = <span class="Constant">false</span>;
<span id="L90" class="LineNr"> 90 </span>    delegates.clear();
<span id="L91" class="LineNr"> 91 </span>  }
<span id="L92" class="LineNr"> 92 </span>
<span id="L93" class="LineNr"> 93 </span>  <span class="Type">void</span> run(Object[] inputs, Map&lt;Integer, Object&gt; outputs) {
<span id="L94" class="LineNr"> 94 </span>    inferenceDurationNanoseconds = -<span class="Constant">1</span>;
<span id="L95" class="LineNr"> 95 </span>    <span class="Statement">if</span> (inputs == <span class="Constant">null</span> || inputs.length == <span class="Constant">0</span>) {
<span id="L96" class="LineNr"> 96 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(<span class="Constant">&quot;Input error: Inputs should not be null or empty.&quot;</span>);
<span id="L97" class="LineNr"> 97 </span>    }
<span id="L98" class="LineNr"> 98 </span>    <span class="Statement">if</span> (outputs == <span class="Constant">null</span> || outputs.isEmpty()) {
<span id="L99" class="LineNr"> 99 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(<span class="Constant">&quot;Input error: Outputs should not be null or empty.&quot;</span>);
<span id="L100" class="LineNr">100 </span>    }
<span id="L101" class="LineNr">101 </span>
<span id="L102" class="LineNr">102 </span>    <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; inputs.length; ++i) {
<span id="L103" class="LineNr">103 </span>      Tensor tensor = getInputTensor(i);
<span id="L104" class="LineNr">104 </span>      <span class="Type">int</span>[] newShape = tensor.getInputShapeIfDifferent(inputs[i]);
<span id="L105" class="LineNr">105 </span>      <span class="Statement">if</span> (newShape != <span class="Constant">null</span>) {
<span id="L106" class="LineNr">106 </span>        resizeInput(i, newShape);
<span id="L107" class="LineNr">107 </span>      }
<span id="L108" class="LineNr">108 </span>    }
<span id="L109" class="LineNr">109 </span>
<span id="L110" class="LineNr">110 </span>    <span class="Type">boolean</span> needsAllocation = !isMemoryAllocated;
<span id="L111" class="LineNr">111 </span>    <span class="Statement">if</span> (needsAllocation) {
<span id="L112" class="LineNr">112 </span>      allocateTensors(interpreterHandle, errorHandle);
<span id="L113" class="LineNr">113 </span>      isMemoryAllocated = <span class="Constant">true</span>;
<span id="L114" class="LineNr">114 </span>    }
<span id="L115" class="LineNr">115 </span>
<span id="L116" class="LineNr">116 </span>    <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; inputs.length; ++i) {
<span id="L117" class="LineNr">117 </span>      getInputTensor(i).setTo(inputs[i]);
<span id="L118" class="LineNr">118 </span>    }
<span id="L119" class="LineNr">119 </span>
<span id="L120" class="LineNr">120 </span>    <span class="Type">long</span> inferenceStartNanos = System.nanoTime();
<span id="L121" class="LineNr">121 </span>    run(interpreterHandle, errorHandle);
<span id="L122" class="LineNr">122 </span>    <span class="Type">long</span> inferenceDurationNanoseconds = System.nanoTime() - inferenceStartNanos;
<span id="L123" class="LineNr">123 </span>
<span id="L124" class="LineNr">124 </span>    <span class="Comment">// Allocation can trigger dynamic resizing of output tensors, so refresh all output shapes.</span>
<span id="L125" class="LineNr">125 </span>    <span class="Statement">if</span> (needsAllocation) {
<span id="L126" class="LineNr">126 </span>      <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; outputTensors.length; ++i) {
<span id="L127" class="LineNr">127 </span>        <span class="Statement">if</span> (outputTensors[i] != <span class="Constant">null</span>) {
<span id="L128" class="LineNr">128 </span>          outputTensors[i].refreshShape();
<span id="L129" class="LineNr">129 </span>        }
<span id="L130" class="LineNr">130 </span>      }
<span id="L131" class="LineNr">131 </span>    }
<span id="L132" class="LineNr">132 </span>    <span class="Statement">for</span> (Map.Entry&lt;Integer, Object&gt; output : outputs.entrySet()) {
<span id="L133" class="LineNr">133 </span>      getOutputTensor(output.getKey()).copyTo(output.getValue());
<span id="L134" class="LineNr">134 </span>    }
<span id="L135" class="LineNr">135 </span>
<span id="L136" class="LineNr">136 </span>    <span class="Type">this</span>.inferenceDurationNanoseconds = inferenceDurationNanoseconds;
<span id="L137" class="LineNr">137 </span>  }
<span id="L138" class="LineNr">138 </span>
<span id="L139" class="LineNr">139 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">boolean</span> run(<span class="Type">long</span> interpreterHandle, <span class="Type">long</span> errorHandle);
<span id="L140" class="LineNr">140 </span>
<span id="L141" class="LineNr">141 </span>  <span class="Type">void</span> resizeInput(<span class="Type">int</span> idx, <span class="Type">int</span>[] dims) {
<span id="L142" class="LineNr">142 </span>    <span class="Statement">if</span> (resizeInput(interpreterHandle, errorHandle, idx, dims)) {
<span id="L143" class="LineNr">143 </span>      isMemoryAllocated = <span class="Constant">false</span>;
<span id="L144" class="LineNr">144 </span>      <span class="Statement">if</span> (inputTensors[idx] != <span class="Constant">null</span>) {
<span id="L145" class="LineNr">145 </span>        inputTensors[idx].refreshShape();
<span id="L146" class="LineNr">146 </span>      }
<span id="L147" class="LineNr">147 </span>    }
<span id="L148" class="LineNr">148 </span>  }
<span id="L149" class="LineNr">149 </span>
<span id="L150" class="LineNr">150 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">boolean</span> resizeInput(
<span id="L151" class="LineNr">151 </span>      <span class="Type">long</span> interpreterHandle, <span class="Type">long</span> errorHandle, <span class="Type">int</span> inputIdx, <span class="Type">int</span>[] dims);
<span id="L152" class="LineNr">152 </span>
<span id="L153" class="LineNr">153 </span>  <span class="Type">void</span> setUseNNAPI(<span class="Type">boolean</span> useNNAPI) {
<span id="L154" class="LineNr">154 </span>    useNNAPI(interpreterHandle, useNNAPI);
<span id="L155" class="LineNr">155 </span>  }
<span id="L156" class="LineNr">156 </span>
<span id="L157" class="LineNr">157 </span>  <span class="Type">void</span> setNumThreads(<span class="Type">int</span> numThreads) {
<span id="L158" class="LineNr">158 </span>    numThreads(interpreterHandle, numThreads);
<span id="L159" class="LineNr">159 </span>  }
<span id="L160" class="LineNr">160 </span>
<span id="L161" class="LineNr">161 </span>  <span class="Type">void</span> modifyGraphWithDelegate(Delegate delegate) {
<span id="L162" class="LineNr">162 </span>    applyDelegate(interpreterHandle, errorHandle, delegate.getNativeHandle());
<span id="L163" class="LineNr">163 </span>    delegates.add(delegate);
<span id="L164" class="LineNr">164 </span>  }
<span id="L165" class="LineNr">165 </span>
<span id="L166" class="LineNr">166 </span>  <span class="Type">int</span> getInputIndex(String name) {
<span id="L167" class="LineNr">167 </span>    <span class="Statement">if</span> (inputsIndexes == <span class="Constant">null</span>) {
<span id="L168" class="LineNr">168 </span>      String[] names = getInputNames(interpreterHandle);
<span id="L169" class="LineNr">169 </span>      inputsIndexes = <span class="Statement">new</span> HashMap&lt;&gt;();
<span id="L170" class="LineNr">170 </span>      <span class="Statement">if</span> (names != <span class="Constant">null</span>) {
<span id="L171" class="LineNr">171 </span>        <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; names.length; ++i) {
<span id="L172" class="LineNr">172 </span>          inputsIndexes.put(names[i], i);
<span id="L173" class="LineNr">173 </span>        }
<span id="L174" class="LineNr">174 </span>      }
<span id="L175" class="LineNr">175 </span>    }
<span id="L176" class="LineNr">176 </span>    <span class="Statement">if</span> (inputsIndexes.containsKey(name)) {
<span id="L177" class="LineNr">177 </span>      <span class="Statement">return</span> inputsIndexes.get(name);
<span id="L178" class="LineNr">178 </span>    } <span class="Statement">else</span> {
<span id="L179" class="LineNr">179 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(
<span id="L180" class="LineNr">180 </span>          String.format(
<span id="L181" class="LineNr">181 </span>              <span class="Constant">&quot;Input error: '%s' is not a valid name for any input. Names of inputs and their &quot;</span>
<span id="L182" class="LineNr">182 </span>                  + <span class="Constant">&quot;indexes are %s&quot;</span>,
<span id="L183" class="LineNr">183 </span>              name, inputsIndexes.toString()));
<span id="L184" class="LineNr">184 </span>    }
<span id="L185" class="LineNr">185 </span>  }
<span id="L186" class="LineNr">186 </span>
<span id="L187" class="LineNr">187 </span>  <span class="Type">int</span> getOutputIndex(String name) {
<span id="L188" class="LineNr">188 </span>    <span class="Statement">if</span> (outputsIndexes == <span class="Constant">null</span>) {
<span id="L189" class="LineNr">189 </span>      String[] names = getOutputNames(interpreterHandle);
<span id="L190" class="LineNr">190 </span>      outputsIndexes = <span class="Statement">new</span> HashMap&lt;&gt;();
<span id="L191" class="LineNr">191 </span>      <span class="Statement">if</span> (names != <span class="Constant">null</span>) {
<span id="L192" class="LineNr">192 </span>        <span class="Statement">for</span> (<span class="Type">int</span> i = <span class="Constant">0</span>; i &lt; names.length; ++i) {
<span id="L193" class="LineNr">193 </span>          outputsIndexes.put(names[i], i);
<span id="L194" class="LineNr">194 </span>        }
<span id="L195" class="LineNr">195 </span>      }
<span id="L196" class="LineNr">196 </span>    }
<span id="L197" class="LineNr">197 </span>    <span class="Statement">if</span> (outputsIndexes.containsKey(name)) {
<span id="L198" class="LineNr">198 </span>      <span class="Statement">return</span> outputsIndexes.get(name);
<span id="L199" class="LineNr">199 </span>    } <span class="Statement">else</span> {
<span id="L200" class="LineNr">200 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(
<span id="L201" class="LineNr">201 </span>          String.format(
<span id="L202" class="LineNr">202 </span>              <span class="Constant">&quot;Input error: '%s' is not a valid name for any output. Names of outputs and their &quot;</span>
<span id="L203" class="LineNr">203 </span>                  + <span class="Constant">&quot;indexes are %s&quot;</span>,
<span id="L204" class="LineNr">204 </span>              name, outputsIndexes.toString()));
<span id="L205" class="LineNr">205 </span>    }
<span id="L206" class="LineNr">206 </span>  }
<span id="L207" class="LineNr">207 </span>
<span id="L208" class="LineNr">208 </span>  Long getLastNativeInferenceDurationNanoseconds() {
<span id="L209" class="LineNr">209 </span>    <span class="Statement">return</span> (inferenceDurationNanoseconds &lt; <span class="Constant">0</span>) ? <span class="Constant">null</span> : inferenceDurationNanoseconds;
<span id="L210" class="LineNr">210 </span>  }
<span id="L211" class="LineNr">211 </span>
<span id="L212" class="LineNr">212 </span>  <span class="Type">int</span> getOutputQuantizationZeroPoint(<span class="Type">int</span> index) {
<span id="L213" class="LineNr">213 </span>    <span class="Statement">return</span> getOutputQuantizationZeroPoint(interpreterHandle, index);
<span id="L214" class="LineNr">214 </span>  }
<span id="L215" class="LineNr">215 </span>
<span id="L216" class="LineNr">216 </span>  <span class="Type">float</span> getOutputQuantizationScale(<span class="Type">int</span> index) {
<span id="L217" class="LineNr">217 </span>    <span class="Statement">return</span> getOutputQuantizationScale(interpreterHandle, index);
<span id="L218" class="LineNr">218 </span>  }
<span id="L219" class="LineNr">219 </span>
<span id="L220" class="LineNr">220 </span>  <span class="Type">int</span> getInputTensorCount() {
<span id="L221" class="LineNr">221 </span>    <span class="Statement">return</span> inputTensors.length;
<span id="L222" class="LineNr">222 </span>  }
<span id="L223" class="LineNr">223 </span>
<span id="L224" class="LineNr">224 </span>  Tensor getInputTensor(<span class="Type">int</span> index) {
<span id="L225" class="LineNr">225 </span>    <span class="Statement">if</span> (index &lt; <span class="Constant">0</span> || index &gt;= inputTensors.length) {
<span id="L226" class="LineNr">226 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(<span class="Constant">&quot;Invalid input Tensor index: &quot;</span> + index);
<span id="L227" class="LineNr">227 </span>    }
<span id="L228" class="LineNr">228 </span>    Tensor inputTensor = inputTensors[index];
<span id="L229" class="LineNr">229 </span>    <span class="Statement">if</span> (inputTensor == <span class="Constant">null</span>) {
<span id="L230" class="LineNr">230 </span>      inputTensor =
<span id="L231" class="LineNr">231 </span>          inputTensors[index] =
<span id="L232" class="LineNr">232 </span>              Tensor.fromIndex(interpreterHandle, getInputTensorIndex(interpreterHandle, index));
<span id="L233" class="LineNr">233 </span>    }
<span id="L234" class="LineNr">234 </span>    <span class="Statement">return</span> inputTensor;
<span id="L235" class="LineNr">235 </span>  }
<span id="L236" class="LineNr">236 </span>
<span id="L237" class="LineNr">237 </span>  <span class="Type">int</span> getOutputTensorCount() {
<span id="L238" class="LineNr">238 </span>    <span class="Statement">return</span> outputTensors.length;
<span id="L239" class="LineNr">239 </span>  }
<span id="L240" class="LineNr">240 </span>
<span id="L241" class="LineNr">241 </span>  Tensor getOutputTensor(<span class="Type">int</span> index) {
<span id="L242" class="LineNr">242 </span>    <span class="Statement">if</span> (index &lt; <span class="Constant">0</span> || index &gt;= outputTensors.length) {
<span id="L243" class="LineNr">243 </span>      <span class="Statement">throw</span> <span class="Statement">new</span> IllegalArgumentException(<span class="Constant">&quot;Invalid output Tensor index: &quot;</span> + index);
<span id="L244" class="LineNr">244 </span>    }
<span id="L245" class="LineNr">245 </span>    Tensor outputTensor = outputTensors[index];
<span id="L246" class="LineNr">246 </span>    <span class="Statement">if</span> (outputTensor == <span class="Constant">null</span>) {
<span id="L247" class="LineNr">247 </span>      outputTensor =
<span id="L248" class="LineNr">248 </span>          outputTensors[index] =
<span id="L249" class="LineNr">249 </span>              Tensor.fromIndex(interpreterHandle, getOutputTensorIndex(interpreterHandle, index));
<span id="L250" class="LineNr">250 </span>    }
<span id="L251" class="LineNr">251 </span>    <span class="Statement">return</span> outputTensor;
<span id="L252" class="LineNr">252 </span>  }
<span id="L253" class="LineNr">253 </span>
<span id="L254" class="LineNr">254 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getOutputDataType(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> outputIdx);
<span id="L255" class="LineNr">255 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getOutputQuantizationZeroPoint(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> outputIdx);
<span id="L256" class="LineNr">256 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">float</span> getOutputQuantizationScale(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> outputIdx);
<span id="L257" class="LineNr">257 </span>
<span id="L258" class="LineNr">258 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="Type">final</span> <span class="Type">int</span> ERROR_BUFFER_SIZE = <span class="Constant">512</span>;
<span id="L259" class="LineNr">259 </span>
<span id="L260" class="LineNr">260 </span>  <span class="Type">private</span> <span class="Type">long</span> errorHandle;
<span id="L261" class="LineNr">261 </span>  <span class="Type">private</span> <span class="Type">long</span> interpreterHandle;
<span id="L262" class="LineNr">262 </span>  <span class="Type">private</span> <span class="Type">long</span> modelHandle;
<span id="L263" class="LineNr">263 </span>  <span class="Type">private</span> <span class="Type">long</span> inferenceDurationNanoseconds = -<span class="Constant">1</span>;
<span id="L264" class="LineNr">264 </span>  <span class="Type">private</span> ByteBuffer modelByteBuffer;
<span id="L265" class="LineNr">265 </span>  <span class="Type">private</span> Map&lt;String, Integer&gt; inputsIndexes;
<span id="L266" class="LineNr">266 </span>  <span class="Type">private</span> Map&lt;String, Integer&gt; outputsIndexes;
<span id="L267" class="LineNr">267 </span>  <span class="Type">private</span> Tensor[] inputTensors;
<span id="L268" class="LineNr">268 </span>  <span class="Type">private</span> Tensor[] outputTensors;
<span id="L269" class="LineNr">269 </span>  <span class="Type">private</span> <span class="Type">boolean</span> isMemoryAllocated = <span class="Constant">false</span>;
<span id="L270" class="LineNr">270 </span>  <span class="Type">private</span> <span class="Type">final</span> List&lt;Delegate&gt; delegates = <span class="Statement">new</span> ArrayList&lt;&gt;();
<span id="L271" class="LineNr">271 </span>
<span id="L272" class="LineNr">272 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">long</span> allocateTensors(<span class="Type">long</span> interpreterHandle, <span class="Type">long</span> errorHandle);
<span id="L273" class="LineNr">273 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getInputTensorIndex(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> inputIdx);
<span id="L274" class="LineNr">274 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getOutputTensorIndex(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> outputIdx);
<span id="L275" class="LineNr">275 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getInputCount(<span class="Type">long</span> interpreterHandle);
<span id="L276" class="LineNr">276 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">int</span> getOutputCount(<span class="Type">long</span> interpreterHandle);
<span id="L277" class="LineNr">277 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> String[] getInputNames(<span class="Type">long</span> interpreterHandle);
<span id="L278" class="LineNr">278 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> String[] getOutputNames(<span class="Type">long</span> interpreterHandle);
<span id="L279" class="LineNr">279 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> useNNAPI(<span class="Type">long</span> interpreterHandle, <span class="Type">boolean</span> state);
<span id="L280" class="LineNr">280 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> numThreads(<span class="Type">long</span> interpreterHandle, <span class="Type">int</span> numThreads);
<span id="L281" class="LineNr">281 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> allowFp16PrecisionForFp32(<span class="Type">long</span> interpreterHandle, <span class="Type">boolean</span> allow);
<span id="L282" class="LineNr">282 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> allowBufferHandleOutput(<span class="Type">long</span> interpreterHandle, <span class="Type">boolean</span> allow);
<span id="L283" class="LineNr">283 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">long</span> createErrorReporter(<span class="Type">int</span> size);
<span id="L284" class="LineNr">284 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">long</span> createModel(String modelPathOrBuffer, <span class="Type">long</span> errorHandle);
<span id="L285" class="LineNr">285 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">long</span> createModelWithBuffer(ByteBuffer modelBuffer, <span class="Type">long</span> errorHandle);
<span id="L286" class="LineNr">286 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">long</span> createInterpreter(<span class="Type">long</span> modelHandle, <span class="Type">long</span> errorHandle, <span class="Type">int</span> numThreads);
<span id="L287" class="LineNr">287 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> applyDelegate(
<span id="L288" class="LineNr">288 </span>      <span class="Type">long</span> interpreterHandle, <span class="Type">long</span> errorHandle, <span class="Type">long</span> delegateHandle);
<span id="L289" class="LineNr">289 </span>  <span class="Type">private</span> <span class="Type">static</span> <span class="PreProc">native</span> <span class="Type">void</span> delete(<span class="Type">long</span> errorHandle, <span class="Type">long</span> modelHandle, <span class="Type">long</span> interpreterHandle);
<span id="L290" class="LineNr">290 </span>
<span id="L291" class="LineNr">291 </span>  <span class="Type">static</span> {
<span id="L292" class="LineNr">292 </span>    TensorFlowLite.init();
<span id="L293" class="LineNr">293 </span>  }
<span id="L294" class="LineNr">294 </span>}
</pre>
</body>
</html>
<!-- vim: set foldmethod=manual : -->
